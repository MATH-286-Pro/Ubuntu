# [MICRO-507] Legged Robots 足式机器人

## 成绩构成
- Presentation (20%)
- Project
  - 3 人一组
- Exam

## 课程内容


## **Presentation**

#### 大致内容
Presentations of articles: Students will chose one article among a list of key articles in legged robots. The purpose is to carefully read the article, critically analyze its pros and cons, and present it to the class. The presentation will be graded by the professor and teaching assistants (TAs). The list of articles will soon be provided, and a schedule will be organized after 2-3 weeks. Each student in the 3-person team should participate to the presentation.

学生将从腿式机器人的关键论文列表中选择一篇论文。目的是仔细阅读该论文，批判性地分析其**优缺点**，并向全班展示。教授和助教 (TA) 将对论文展示进行评分。论文列表将很快提供，并在 2-3 周后安排时间表。3 人团队中的每个学生都应参加论文展示


文章演示是课程的重要组成部分，因为它们使我们能够更深入地了解讲座中介绍的一些主题。请务必查看其他学生的演示，因为一些考试问题将涵盖学生演示的材料。

#### 指示
- 时长：8 分钟（严格限制） +4 分钟提问
- 新：今年除了在课堂上进行现场演示外，我们还要求您在现场演示的前一天提供 8 分钟的预录演示视频。我们建议您使用带有“在此计算机上录制”选项的 zoom。这些视频将在 Moodle 上共享。
- 小组内所有学生都应参加演讲。

#### 演示内容
- **首先对文章的主要思想/贡献进行简要总结**
- 对关键方面进行执行总结，例如哪种类型的机器人（双足机器人、四足机器人等）、哪种类型的控制（例如位置、阻抗或扭矩控制）、哪种类型的设计方法（手动调整、基于数学证明、优化、强化学习、进化算法等）、哪种类型的步态（步行、跑步、小跑、多种步态）、使用哪些类型的主要传感器等。
详细介绍文章，包括图表、方程式、结果、视频等。
- 查看谁引用了这篇文章，可以在Google 学术或Scopus上找到。检查该方法是否影响了其他实验室（例如，在其他机器人上重复使用）。还要查看该方法是否因某种原因受到批评。
- 最后以优缺点分析作为结论（例如以项目符号列表的形式）。
- 最后一张幻灯片：添加有关文章的 2 个可能的考试问题 + 简短答案（或指向在哪里可以找到答案的幻灯片的指针）。
- 在演示日的前一天晚上，将录制的视频（mp4）和演示文稿上传至 Moodle（pdf）

#### 提示：
- 请仔细检查你的时间，并排练几次
- 包括图表，并确保其可读（大格式）
- 尝试包含视频（例如，当作为期刊网站上的补充材料提供时，或通过搜索作者的网站）
- 不要犹豫，先展示一段视频（例如，展示已经取得的成就，然后说“现在我们将解释这是如何实现的......”）


## 针对展示论文

#### 文章内容
- 研究问题：机器人的视觉 + 跳跃
- 主要思想：
- 控制：力矩控制
- 设计：强化学习 + 
- 步态：好像什么都有
- 传感器：Intel RealSense D435 (深度摄像头)

#### 展示顺序
- 研究问题
- 方案设计
- 方案效果
- 我们觉得怎么样

#### 谁引用了这篇文章 (84个引用)
- 2022 MIT [Rapid locomotion via reinforcement learning](https://agility.csail.mit.edu/) (机器人快速运动) (自己的实验室)
- 2023 ShuangHai Qi Zhi [Robot Parkour Learning](https://robot-parkour.github.io/) (同样使用深度摄像机 跑酷)
- 2023 UCB [Learning and Adapting Agility Skills by Transferring Experience](https://sites.google.com/berkeley.edu/twirl)
- 2022 EPFL [CPG-RL: Learning Central Pattern Generators for Quadruped Locomotion](https://ieeexplore.ieee.org/abstract/document/9932888)
- 2023 UCSD [Neural Volumetric Memory for Visual Locomotion Control](https://rchalyang.github.io/NVM/) (使用当前加上之前的图像融合，判断脚底的地形)
- 2023 CMU + UCB [Legged Locomotion in Challenging Terrains using Egocentric Vision](https://proceedings.mlr.press/v205/agarwal23a.html) (使用RNN记忆之前的图像信息)